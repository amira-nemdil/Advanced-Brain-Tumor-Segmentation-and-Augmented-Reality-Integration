{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1cc1b29",
   "metadata": {},
   "source": [
    "# 🧠 BraTS2021 U-Net & Attention U-Net Training Script\n",
    "This notebook trains segmentation models on the BraTS2021 dataset using U-Net and Attention U-Net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e79e544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Advanced Brain Tumor Segmentation and Augmented Reality Integration\\.venv\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "❌ No GPU found. Training will be slow.\n",
      "Num GPUs Available: 0\n",
      "Physical Devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 14844116907921033471\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "DATASET_DIR = r\"D:\\Khedir-meriem-ESI-SBElAbes\\data\\BraTS2021_Training_Data\"\n",
    "IMAGE_SIZE = 256\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 30\n",
    "SEED = 42\n",
    "\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name:\n",
    "    print(f\"✅ GPU detected: {device_name}\")\n",
    "else:\n",
    "    print(\"❌ No GPU found. Training will be slow.\")\n",
    "\n",
    "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"Physical Devices:\", tf.config.list_physical_devices())\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be02ee54",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_dirs = sorted(glob.glob(os.path.join(DATASET_DIR, \"BraTS2021_*\")))\n",
    "image_files = []\n",
    "mask_files = []\n",
    "\n",
    "for subject in subject_dirs:\n",
    "    t1ce_path = glob.glob(os.path.join(subject, \"*_t1ce.nii.gz\"))\n",
    "    seg_path = glob.glob(os.path.join(subject, \"*_seg.nii.gz\"))\n",
    "    if t1ce_path and seg_path:\n",
    "        image_files.append(t1ce_path[0])\n",
    "        mask_files.append(seg_path[0])\n",
    "\n",
    "print(\"✅ Found images:\", len(image_files))\n",
    "print(\"✅ Found masks:\", len(mask_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d69d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nifti_image(path):\n",
    "    img = nib.load(path)\n",
    "    return img.get_fdata()\n",
    "\n",
    "def preprocess_image(image, mask):\n",
    "    mid_slice = image.shape[2] // 2\n",
    "    image = image[:, :, mid_slice]\n",
    "    mask = mask[:, :, mid_slice]\n",
    "    image = tf.image.resize(image[..., np.newaxis], (IMAGE_SIZE, IMAGE_SIZE))\n",
    "    mask = tf.image.resize(mask[..., np.newaxis], (IMAGE_SIZE, IMAGE_SIZE))\n",
    "    image = tf.cast(image, tf.float32) / tf.reduce_max(image)\n",
    "    mask = tf.cast(mask > 0, tf.float32)\n",
    "    return image, mask\n",
    "\n",
    "def augment_image(image, mask):\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        image = tf.image.flip_left_right(image)\n",
    "        mask = tf.image.flip_left_right(mask)\n",
    "    k = tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32)\n",
    "    image = tf.image.rot90(image, k)\n",
    "    mask = tf.image.rot90(mask, k)\n",
    "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
    "    return image, mask\n",
    "\n",
    "def data_generator(image_paths, mask_paths, augment=False):\n",
    "    while True:\n",
    "        for img_path, mask_path in zip(image_paths, mask_paths):\n",
    "            img = load_nifti_image(img_path)\n",
    "            mask = load_nifti_image(mask_path)\n",
    "            image, mask = preprocess_image(img, mask)\n",
    "            if augment:\n",
    "                image, mask = augment_image(image, mask)\n",
    "            yield tf.expand_dims(image, 0), tf.expand_dims(mask, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604cdd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_model(input_size=(IMAGE_SIZE, IMAGE_SIZE, 1)):\n",
    "    inputs = layers.Input(input_size)\n",
    "    c1 = layers.Conv2D(16, 3, activation='relu', padding='same')(inputs)\n",
    "    c1 = layers.Conv2D(16, 3, activation='relu', padding='same')(c1)\n",
    "    p1 = layers.MaxPooling2D()(c1)\n",
    "    c2 = layers.Conv2D(32, 3, activation='relu', padding='same')(p1)\n",
    "    c2 = layers.Conv2D(32, 3, activation='relu', padding='same')(c2)\n",
    "    p2 = layers.MaxPooling2D()(c2)\n",
    "    c3 = layers.Conv2D(64, 3, activation='relu', padding='same')(p2)\n",
    "    c3 = layers.Conv2D(64, 3, activation='relu', padding='same')(c3)\n",
    "    u1 = layers.UpSampling2D()(c3)\n",
    "    u1 = layers.Concatenate()([u1, c2])\n",
    "    c4 = layers.Conv2D(32, 3, activation='relu', padding='same')(u1)\n",
    "    u2 = layers.UpSampling2D()(c4)\n",
    "    u2 = layers.Concatenate()([u2, c1])\n",
    "    c5 = layers.Conv2D(16, 3, activation='relu', padding='same')(u2)\n",
    "    outputs = layers.Conv2D(1, 1, activation='sigmoid')(c5)\n",
    "    return models.Model(inputs, outputs)\n",
    "\n",
    "def attention_block(x, g, inter_channel):\n",
    "    theta_x = layers.Conv2D(inter_channel, 1)(x)\n",
    "    phi_g = layers.Conv2D(inter_channel, 1)(g)\n",
    "    add = layers.Add()([theta_x, phi_g])\n",
    "    act = layers.Activation('relu')(add)\n",
    "    psi = layers.Conv2D(1, 1, activation='sigmoid')(act)\n",
    "    return layers.Multiply()([x, psi])\n",
    "\n",
    "def attention_unet(input_size=(IMAGE_SIZE, IMAGE_SIZE, 1)):\n",
    "    inputs = layers.Input(input_size)\n",
    "    c1 = layers.Conv2D(16, 3, activation='relu', padding='same')(inputs)\n",
    "    c1 = layers.Conv2D(16, 3, activation='relu', padding='same')(c1)\n",
    "    p1 = layers.MaxPooling2D()(c1)\n",
    "    c2 = layers.Conv2D(32, 3, activation='relu', padding='same')(p1)\n",
    "    c2 = layers.Conv2D(32, 3, activation='relu', padding='same')(c2)\n",
    "    p2 = layers.MaxPooling2D()(c2)\n",
    "    c3 = layers.Conv2D(64, 3, activation='relu', padding='same')(p2)\n",
    "    c3 = layers.Conv2D(64, 3, activation='relu', padding='same')(c3)\n",
    "    g1 = layers.UpSampling2D()(c3)\n",
    "    att1 = attention_block(c2, g1, 32)\n",
    "    u1 = layers.Concatenate()([g1, att1])\n",
    "    c4 = layers.Conv2D(32, 3, activation='relu', padding='same')(u1)\n",
    "    g2 = layers.UpSampling2D()(c4)\n",
    "    att2 = attention_block(c1, g2, 16)\n",
    "    u2 = layers.Concatenate()([g2, att2])\n",
    "    c5 = layers.Conv2D(16, 3, activation='relu', padding='same')(u2)\n",
    "    outputs = layers.Conv2D(1, 1, activation='sigmoid')(c5)\n",
    "    return models.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecca2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, model_name, train_gen, val_gen, steps_per_epoch, val_steps):\n",
    "    print(f\"Training {model_name}...\")\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.ModelCheckpoint(f\"{model_name}_best.h5\", save_best_only=True),\n",
    "        tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True),\n",
    "        tf.keras.callbacks.TensorBoard(log_dir=f\"./logs/{model_name}\")\n",
    "    ]\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(train_gen, validation_data=val_gen,\n",
    "                        steps_per_epoch=steps_per_epoch,\n",
    "                        validation_steps=val_steps,\n",
    "                        epochs=EPOCHS, callbacks=callbacks)\n",
    "    model.save(f\"{model_name}.h5\")\n",
    "    return history\n",
    "\n",
    "split_index = int(len(image_files) * 0.8)\n",
    "train_images, val_images = image_files[:split_index], image_files[split_index:]\n",
    "train_masks, val_masks = mask_files[:split_index], mask_files[split_index:]\n",
    "\n",
    "steps_per_epoch = math.ceil(len(train_images) / BATCH_SIZE)\n",
    "val_steps = math.ceil(len(val_images) / BATCH_SIZE)\n",
    "\n",
    "train_gen = data_generator(train_images, train_masks, augment=True)\n",
    "val_gen = data_generator(val_images, val_masks)\n",
    "\n",
    "unet = unet_model()\n",
    "history_unet = train_model(unet, \"unet_model\", train_gen, val_gen, steps_per_epoch, val_steps)\n",
    "\n",
    "attention = attention_unet()\n",
    "train_gen = data_generator(train_images, train_masks, augment=True)\n",
    "val_gen = data_generator(val_images, val_masks)\n",
    "history_attention = train_model(attention, \"attention_unet_model\", train_gen, val_gen, steps_per_epoch, val_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cc5c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history, title):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history_unet, \"U-Net Training History\")\n",
    "plot_history(history_attention, \"Attention U-Net Training History\")\n",
    "\n",
    "print(\"✅ All training finished successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
